<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Smart Face Attendance</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<style>
    body {
        font-family: Arial, sans-serif;
        background: #0f172a;
        color: #fff;
        text-align: center;
        padding: 20px;
    }

    h1 {
        color: #4ade80;
        margin-bottom: 10px;
    }

    video {
        border-radius: 12px;
        border: 2px solid #4ade80;
        width: 360px;
        height: auto;
        margin-top: 10px;
    }

    canvas {
        position: absolute;
        left: 50%;
        transform: translateX(-50%);
    }

    #messageBox {
        margin-top: 15px;
        font-size: 18px;
        padding: 10px;
        border-radius: 10px;
        display: none;
    }

    .success {
        background: #14532d;
        border: 1px solid #4ade80;
    }

    .error {
        background: #450a0a;
        border: 1px solid #ef4444;
    }

    .dash {
        margin-top: 25px;
        display: flex;
        justify-content: space-around;
        flex-wrap: wrap;
    }

    .box {
        background: #1e293b;
        padding: 15px;
        border-radius: 10px;
        width: 45%;
        min-width: 250px;
    }

    .present {
        color: #4ade80;
    }

    .pending {
        color: #fbbf24;
    }

</style>
</head>
<body>

<h1>SMART FACE ATTENDANCE SYSTEM</h1>
<p>Face Recognition will automatically mark attendance for registered students.</p>

<!-- CAMERA AREA -->
<video id="video" autoplay></video>
<canvas id="canvas"></canvas>

<div id="messageBox"></div>

<!-- DASHBOARD -->
<div class="dash">
    <div class="box">
        <h3 class="present">Present Students</h3>
        <ul id="presentList"></ul>
    </div>

    <div class="box">
        <h3 class="pending">Pending Students</h3>
        <ul id="pendingList"></ul>
    </div>
</div>

<!-- FACE API JS -->
<script src="https://cdn.jsdelivr.net/npm/face-api.js"></script>

<script>

// Student list
const students = [
    { name: "Keerthana", file: "students/Keerthana.jpeg" },
    { name: "Hari Chandana", file: "students/Hari_Chandana.jpeg" },
    { name: "Vedha Sai G", file: "students/Vedha_Sai_G.jpeg" },
    { name: "Ajith Kumar", file: "students/Ajith_Kumar.jpeg" },
    { name: "Shiva Narayana", file: "students/Shiva_Narayana.jpeg" }
];

let present = [];
let pending = students.map(s => s.name);

// Update dashboard
function updateDashboard() {
    document.getElementById("presentList").innerHTML =
        present.map(x => `<li> ${x} ✔</li>`).join("");

    document.getElementById("pendingList").innerHTML =
        pending.map(x => `<li> ${x} ⏳</li>`).join("");
}

updateDashboard();

// Show message
function showMessage(type, text) {
    let box = document.getElementById("messageBox");
    box.style.display = "block";
    box.innerHTML = text;

    if (type === "success") {
        box.className = "success";
    } else {
        box.className = "error";
    }
}

// Load models + student images
Promise.all([
    faceapi.nets.tinyFaceDetector.loadFromUri("models"),
    faceapi.nets.faceLandmark68Net.loadFromUri("models"),
    faceapi.nets.faceRecognitionNet.loadFromUri("models")
]).then(loadFaces);

// Creating labeled face descriptors
async function loadFaces() {
    const labeled = [];

    for (const s of students) {
        const img = await faceapi.fetchImage(s.file);
        const det = await faceapi.detectSingleFace(img,
            new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceDescriptor();

        labeled.push(new faceapi.LabeledFaceDescriptors(s.name, [det.descriptor]));
    }

    startCamera(labeled);
}

// Start camera
async function startCamera(labeledFaces) {
    const video = document.getElementById("video");

    const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
    video.srcObject = stream;

    video.addEventListener('play', () => {
        const canvas = document.getElementById("canvas");
        const ctx = canvas.getContext("2d");

        canvas.width = video.width;
        canvas.height = video.height;

        const matcher = new faceapi.FaceMatcher(labeledFaces, 0.45);

        setInterval(async () => {
            const det = await faceapi.detectAllFaces(video,
                new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceDescriptors();

            ctx.clearRect(0, 0, canvas.width, canvas.height);

            const resized = faceapi.resizeResults(det, {
                width: canvas.width,
                height: canvas.height
            });

            resized.forEach(d => {
                const box = d.detection.box;
                ctx.strokeStyle = "#4ade80";
                ctx.lineWidth = 2;
                ctx.strokeRect(box.x, box.y, box.width, box.height);

                const bestMatch = matcher.findBestMatch(d.descriptor).label;

                ctx.fillStyle = "black";
                ctx.fillText(bestMatch, box.x, box.y - 5);

                if (bestMatch !== "unknown" && pending.includes(bestMatch)) {
                    present.push(bestMatch);
                    pending = pending.filter(n => n !== bestMatch);
                    showMessage("success", `✔ Attendance taken for <b>${bestMatch}</b>`);
                    updateDashboard();
                }
            });

        }, 300);
    });
}

</script>

<div style="margin-top:20px;opacity:0.7;">
    Developed by <b>Keerthana</b> & <b>Hari Chandhana</b>
</div>

</body>
</html>
